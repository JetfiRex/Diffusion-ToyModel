{
 "cells": [
  {
   "cell_type": "code",
   "id": "674afcd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T03:06:15.885949Z",
     "start_time": "2025-12-22T03:06:15.878982Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "torch.backends.cudnn.allow_tf32 = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def make_projection(D, d, device=device):\n",
    "    A = torch.randn(D, d, device=\"cpu\")\n",
    "    Q, _ = torch.linalg.qr(A)  \n",
    "    Q = Q.to(device)\n",
    "    return Q  \n",
    "\n",
    "def sample_underlying_2d(n_points):\n",
    "    theta = np.linspace(0, 4 * np.pi, n_points)\n",
    "    r = theta / (4 * np.pi) * 2.0  \n",
    "\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "\n",
    "    pts = np.stack([x, y], axis=1)\n",
    "\n",
    "    pts += 0.02 * np.random.randn(*pts.shape)\n",
    "    pts = torch.from_numpy(pts).float()\n",
    "    return pts   "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "b5c15ba9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T03:06:15.923608Z",
     "start_time": "2025-12-22T03:06:15.915300Z"
    }
   },
   "source": [
    "class MLP5(nn.Module):\n",
    "    def __init__(self, x_dim, hidden_dim, out_dim, t_dim=None):\n",
    "        \"\"\"\n",
    "        x_dim: D  (x is [B, D])\n",
    "        t_dim: D  (t is [B, D]) by default\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.x_dim = x_dim\n",
    "        self.t_dim = x_dim if t_dim is None else t_dim\n",
    "\n",
    "        in_dim = self.x_dim + self.t_dim\n",
    "\n",
    "        layers = []\n",
    "        dims = [in_dim] + [hidden_dim] * 5 + [out_dim]\n",
    "        for i in range(len(dims) - 2):\n",
    "            layers.append(nn.Linear(dims[i], dims[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        x: [B, D]\n",
    "        t: [B, D]  (per-dim time)\n",
    "           (also allows [B] or [B,1], which will be broadcast to [B, t_dim])\n",
    "        \"\"\"\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(-1)  # [B, 1]\n",
    "\n",
    "        if t.dim() == 2 and t.shape[1] == 1 and self.t_dim != 1:\n",
    "            # broadcast scalar time to per-dim time if user passes [B,1]\n",
    "            t = t.expand(-1, self.t_dim)  # [B, t_dim]\n",
    "\n",
    "        assert x.dim() == 2 and x.shape[1] == self.x_dim, f\"x should be [B, {self.x_dim}]\"\n",
    "        assert t.dim() == 2 and t.shape[1] == self.t_dim, f\"t should be [B, {self.t_dim}]\"\n",
    "\n",
    "        t = t.to(dtype=x.dtype, device=x.device)\n",
    "        inp = torch.cat([x, t], dim=-1)  # [B, D + t_dim]\n",
    "        return self.net(inp)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "503a779c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T03:06:15.949650Z",
     "start_time": "2025-12-22T03:06:15.937822Z"
    }
   },
   "source": [
    "def train_toy(\n",
    "    D=16,\n",
    "    d=2,\n",
    "    target_type=\"x\",\n",
    "    n_samples=20000,\n",
    "    batch_size=1024,\n",
    "    epochs=500,\n",
    "    lr=1e-3,\n",
    "):\n",
    "    P = make_projection(D, d)  # [D, 2]\n",
    "    x_hat = sample_underlying_2d(n_samples).to(device)  # [N, 2]\n",
    "    x = x_hat @ P.t()  \n",
    "    \n",
    "    sigma = x.std() / 3.0\n",
    "    print(f\"Data std: {x.std().item():.4f}\")\n",
    "    print(f\"Using sigma: {sigma.item():.4f}\")\n",
    "    print(f\"Data shape: {x.shape}\")\n",
    "\n",
    "    dataset = TensorDataset(x)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    model = MLP5(x_dim=D, hidden_dim=256, out_dim=D, t_dim=D).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in tqdm(range(epochs), desc=f\"Training D={D}, target={target_type}\"):\n",
    "        for step, (x_batch,) in enumerate(loader):\n",
    "            x_1 = x_batch.to(device)  # [B, D]\n",
    "\n",
    "            B = x_1.size(0)\n",
    "            x_1 = x_1 / sigma\n",
    "\n",
    "            #  t ~ Uniform(0,1), asychronous time for each dim\n",
    "            t = torch.rand((B, D), device=device)\n",
    "            \n",
    "            x_0 = torch.randn_like(x_1)\n",
    "            x_t = t * x_1 + (1 - t) * x_0\n",
    "            # [B, 2] * [B, 2] + [B, 2] * [B, 2]\n",
    "            \n",
    "            model_pred = model(x_t, t)\n",
    "\n",
    "            if target_type == \"data\":\n",
    "                dnorm = torch.clamp(1. - t, min=0.05)\n",
    "                v_target = (x_1 - x_t) / dnorm\n",
    "                v_pred = (model_pred - x_t) / dnorm\n",
    "                loss = ((v_target - v_pred) ** 2).mean()\n",
    "\n",
    "            elif target_type == \"v\":\n",
    "                v_target = x_1 - x_0\n",
    "                loss = ((v_target - model_pred) ** 2).mean()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        if (epoch + 1) % 50 == 0 or epoch == 0:\n",
    "            print(f\"[D={D}] Epoch {epoch + 1}/{epochs} | {target_type}-prediction loss: {loss.item():.4f}\")\n",
    "\n",
    "    return model, P, x_hat, x, sigma\n",
    "\n",
    "\n",
    "def show_point(x, P, x_hat_true, target_type, D, cur_step=None):\n",
    "    \n",
    "    pred_2d = x @ P  # [N,2]\n",
    "\n",
    "    x_hat_np = x_hat_true.cpu().numpy()\n",
    "    pred_2d_np = pred_2d.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(x_hat_np[:, 0], x_hat_np[:, 1], s=5, alpha=0.3, label=\"True 2D data\")\n",
    "    plt.scatter(pred_2d_np[:, 0], pred_2d_np[:, 1], s=5, alpha=0.7, label=f\"Generated ({target_type}-pred)\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"D={D}, target={target_type}\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.tight_layout()\n",
    "    save_filename = f\"toy_D{D}_target_{target_type}_step_{cur_step}.png\" if cur_step is not None else f\"toy_D{D}_target_{target_type}.png\"\n",
    "    plt.savefig(save_filename, dpi=200)\n",
    "\n",
    "\n",
    "def visualize_2d(model, P, n_points=2000, target_type=\"x\", steps=250, x_true=None, sigma=1.0):\n",
    "    \n",
    "    model.eval()\n",
    "    P = P.to(device)\n",
    "    D, d = P.shape  # P: [D,2]\n",
    "\n",
    "    x = torch.randn(n_points, D, device=device)\n",
    "    dt = 1.0 / steps\n",
    "\n",
    "    for i in range(steps):\n",
    "        with torch.no_grad():\n",
    "            t = torch.full((n_points, D), i * dt, device=device) \n",
    "            x_t = x                                            \n",
    "\n",
    "            pred = model(x_t, t)\n",
    "            \n",
    "            if target_type == \"data\":\n",
    "                vp = (pred - x_t) / (1. - t)   \n",
    "            elif target_type == \"data_scaled\":\n",
    "                vp = pred / (1. - t)\n",
    "            elif target_type == \"v\":\n",
    "                vp = pred\n",
    "            \n",
    "            x = x_t + dt * vp  \n",
    "            # if i % 50 == 0 or i == 1:\n",
    "            #     show_point((x_t - i * dt * vp) * sigma, P, x_hat_true, target_type, D, cur_step=i)\n",
    "\n",
    "    show_point(x * sigma, P, x_true, target_type, D)\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "96f03b84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T03:06:37.518659Z",
     "start_time": "2025-12-22T03:06:37.414575Z"
    }
   },
   "source": [
    "Ds = [4, 16, 512]\n",
    "target_types = [\"data\", \"v\"]\n",
    "\n",
    "for D in Ds:\n",
    "    for tt in target_types:\n",
    "        print(f\"\\n=== Training D={D}, target={tt} ===\")\n",
    "        model, P, x_hat, x, sigma = train_toy(\n",
    "            D=D,\n",
    "            d=2,\n",
    "            target_type=tt,\n",
    "            n_samples=20000,\n",
    "            batch_size=1024,\n",
    "            epochs=500, \n",
    "            lr=1e-3,\n",
    "        )\n",
    "        visualize_2d(model, P, n_points=20000, target_type=tt, x_true=x_hat, sigma=sigma)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training D=4, target=data ===\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAssertionError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m tt \u001B[38;5;129;01min\u001B[39;00m target_types:\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33m=== Training D=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mD\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, target=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtt\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m ===\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     model, P, x_hat, x, sigma = \u001B[43mtrain_toy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[43mD\u001B[49m\u001B[43m=\u001B[49m\u001B[43mD\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m        \u001B[49m\u001B[43md\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtarget_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m20000\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1024\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     13\u001B[39m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m500\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[32m     14\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1e-3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m     visualize_2d(model, P, n_points=\u001B[32m20000\u001B[39m, target_type=tt, x_true=x_hat, sigma=sigma)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mtrain_toy\u001B[39m\u001B[34m(D, d, target_type, n_samples, batch_size, epochs, lr)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtrain_toy\u001B[39m(\n\u001B[32m      2\u001B[39m     D=\u001B[32m16\u001B[39m,\n\u001B[32m      3\u001B[39m     d=\u001B[32m2\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m      8\u001B[39m     lr=\u001B[32m1e-3\u001B[39m,\n\u001B[32m      9\u001B[39m ):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     P = \u001B[43mmake_projection\u001B[49m\u001B[43m(\u001B[49m\u001B[43mD\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# [D, 2]\u001B[39;00m\n\u001B[32m     11\u001B[39m     x_hat = sample_underlying_2d(n_samples).to(device)  \u001B[38;5;66;03m# [N, 2]\u001B[39;00m\n\u001B[32m     12\u001B[39m     x = x_hat @ P.t()  \n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mmake_projection\u001B[39m\u001B[34m(D, d, device)\u001B[39m\n\u001B[32m     17\u001B[39m A = torch.randn(D, d, device=\u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     18\u001B[39m Q, _ = torch.linalg.qr(A)  \n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m Q = \u001B[43mQ\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m Q\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\Diffusion-ToyModel\\.venv\\Lib\\site-packages\\torch\\cuda\\__init__.py:403\u001B[39m, in \u001B[36m_lazy_init\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    398\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[32m    399\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    400\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mmultiprocessing, you must use the \u001B[39m\u001B[33m'\u001B[39m\u001B[33mspawn\u001B[39m\u001B[33m'\u001B[39m\u001B[33m start method\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    401\u001B[39m     )\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(torch._C, \u001B[33m\"\u001B[39m\u001B[33m_cuda_getDeviceCount\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m--> \u001B[39m\u001B[32m403\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mTorch not compiled with CUDA enabled\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    404\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m _cudart \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    405\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[32m    406\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mlibcudart functions unavailable. It looks like you have a broken build?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    407\u001B[39m     )\n",
      "\u001B[31mAssertionError\u001B[39m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vista-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
